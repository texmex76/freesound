{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3704, 100, 135, 1)\n",
      "Y shape: (3704,)\n",
      "Number tex: 3704\n",
      "Number of categories: 41\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from itertools import islice\n",
    "import gc\n",
    "from natsort import natsorted\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "images_path_base = '/home/bernhard/Documents/ml/freesound/tex_down/'\n",
    "images_ch = images_path_base + 'ch_tex'\n",
    "images_melsp = images_path_base + 'melsp_tex'\n",
    "images_mfcc = images_path_base + 'mfcc_tex'\n",
    "images_sh = images_path_base + 'sh_tex'\n",
    "images_sp = images_path_base + 'sp_tex'\n",
    "\n",
    "m = len(os.listdir(images_ch))\n",
    "\n",
    "cols = ['fname', 'label', 'manually_verified']\n",
    "df = pd.read_csv('train_post_competition.csv', usecols=cols)\n",
    "\n",
    "# Kick out all non-manually verified files\n",
    "df = df[df['manually_verified'] == 1]\n",
    "df = df.drop('manually_verified', axis=1)\n",
    "\n",
    "X_files = np.asarray(df)\n",
    "Y = X_files[:m,1]\n",
    "X_files = []\n",
    "\n",
    "def load_images(path):\n",
    "  image_list = natsorted(os.listdir(path))\n",
    "  loaded_images = []\n",
    "  for image in islice(image_list, m):\n",
    "    with open(os.path.join(path, image), 'rb') as i:\n",
    "      img = Image.open(i)\n",
    "      data = np.asarray(img, dtype='int32')\n",
    "      # data = data[:,:,:3]\n",
    "      loaded_images.append(data)\n",
    "  loaded_images = np.array(loaded_images)\n",
    "  return loaded_images\n",
    "\n",
    "X_ch = load_images(images_ch)\n",
    "X_melsp = load_images(images_melsp)\n",
    "X_mfcc = load_images(images_mfcc)\n",
    "X_sh = load_images(images_sh)\n",
    "X_sp = load_images(images_sp)\n",
    "\n",
    "def reshape_tex(X):\n",
    "  return X.reshape((X.shape[0], X.shape[1], X.shape[2], 1))\n",
    "\n",
    "X_ch = reshape_tex(X_ch)\n",
    "X_melsp = reshape_tex(X_melsp)\n",
    "X_mfcc = reshape_tex(X_mfcc)\n",
    "X_sh = reshape_tex(X_sh)\n",
    "X_sp = reshape_tex(X_sp)\n",
    "\n",
    "print('X shape: {}'.format(X_ch.shape))\n",
    "print('Y shape: {}'.format(Y.shape))\n",
    "print('Number tex: {}'.format(m))\n",
    "\n",
    "Y_one_hot = OneHotEncoder(sparse=False)\n",
    "Y = Y.reshape(Y.shape[0], 1)\n",
    "Y_one_hot_tex = Y_one_hot.fit_transform(Y)\n",
    "print('Number of categories: {}'.format(len(Y_one_hot_tex[0])))\n",
    "\n",
    "random_seed = 2\n",
    "_, X_ch_val, _, _ = train_test_split(X_ch, Y_one_hot_tex,\n",
    "                     test_size = 0.2, random_state=random_seed)\n",
    "\n",
    "_, X_melsp_val, _, Y_val = train_test_split(X_melsp, Y_one_hot_tex,\n",
    "                     test_size = 0.2, random_state=random_seed)\n",
    "\n",
    "_, X_mfcc_val, _, _ = train_test_split(X_mfcc, Y_one_hot_tex,\n",
    "                     test_size = 0.2, random_state=random_seed)\n",
    "\n",
    "_, X_sh_val, _, _ = train_test_split(X_sh, Y_one_hot_tex,\n",
    "                     test_size = 0.2, random_state=random_seed)\n",
    "\n",
    "_, X_sp_val, _, _ = train_test_split(X_sp, Y_one_hot_tex,\n",
    "                     test_size = 0.2, random_state=random_seed)\n",
    "\n",
    "# Clear some memory\n",
    "del df\n",
    "X = []\n",
    "gc.collect()\n",
    "\n",
    "model_mfcc = Sequential([\n",
    "  Conv2D(32, (3,3), strides=1, input_shape=(X_ch_val.shape[1:]), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(64, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(128, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(256, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Dropout(0.25),\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dropout(0.25),\n",
    "  Dense(41, activation='softmax'),\n",
    "])\n",
    "\n",
    "model_sh = Sequential([\n",
    "  Conv2D(32, (3,3), strides=1, input_shape=(X_ch_val.shape[1:]), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(64, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(128, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(256, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Dropout(0.25),\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dropout(0.25),\n",
    "  Dense(41, activation='softmax'),\n",
    "])\n",
    "\n",
    "model_sp = Sequential([\n",
    "  Conv2D(32, (3,3), strides=1, input_shape=(X_ch_val.shape[1:]), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(64, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(128, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(256, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Dropout(0.25),\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dropout(0.25),\n",
    "  Dense(41, activation='softmax'),\n",
    "])\n",
    "\n",
    "model_melsp = Sequential([\n",
    "  Conv2D(32, (3,3), strides=1, input_shape=(X_ch_val.shape[1:]), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(64, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(128, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(256, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Dropout(0.25),\n",
    "  Flatten(),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(64, activation='relu'),\n",
    "  Dropout(0.25),\n",
    "  Dense(41, activation='softmax'),\n",
    "])\n",
    "\n",
    "model_ch = Sequential([\n",
    "  Conv2D(32, (3,3), strides=1, input_shape=(X_ch_val.shape[1:]), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(64, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(128, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "  Conv2D(256, (3,3), strides=1, activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2,2)),\n",
    "#   Dropout(0.25),\n",
    "  Flatten(),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(64, activation='relu'),\n",
    "#   Dropout(0.25),\n",
    "  Dense(41, activation='softmax'),\n",
    "])\n",
    "\n",
    "model_ch.load_weights('weights/model_ch.h5')\n",
    "model_melsp.load_weights('weights/model_melsp.h5')\n",
    "model_mfcc.load_weights('weights/model_mfcc.h5')\n",
    "model_sh.load_weights('weights/model_sh.h5')\n",
    "model_sp.load_weights('weights/model_sp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(741, 41)\n"
     ]
    }
   ],
   "source": [
    "preds_ch = model_ch.predict(X_ch_val, verbose=0)\n",
    "preds_melsp = model_melsp.predict(X_melsp_val, verbose=0)\n",
    "preds_mfcc = model_mfcc.predict(X_mfcc_val, verbose=0)\n",
    "preds_sh = model_sh.predict(X_sh_val, verbose=0)\n",
    "preds_sp = model_sp.predict(X_sp_val, verbose=0)\n",
    "\n",
    "preds_total = (preds_ch + preds_melsp + preds_mfcc + preds_sh + preds_sp) / 5\n",
    "print(preds_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8218623481781376\n"
     ]
    }
   ],
   "source": [
    "preds_total_one_hot = [[i == max(arr) for i in arr] for arr in preds_total]\n",
    "\n",
    "preds = Y_one_hot.inverse_transform(preds_total_one_hot)\n",
    "Y_val_orig = Y_one_hot.inverse_transform(Y_val)\n",
    "\n",
    "comparison = [i == j for i, j in zip(preds, Y_val_orig)]\n",
    "print(np.mean(comparison))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6207827260458839\n"
     ]
    }
   ],
   "source": [
    "# ch, melsp, mfcc, sh, sp\n",
    "preds_one_hot = [[i == max(arr) for i in arr] for arr in preds_mfcc]\n",
    "preds = Y_one_hot.inverse_transform(preds_one_hot)\n",
    "comparison = [i == j for i, j in zip(preds, Y_val_orig)]\n",
    "print(np.mean(comparison))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
